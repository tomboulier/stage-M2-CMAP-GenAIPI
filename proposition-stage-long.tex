\documentclass[11pt,a4paper]{article}

% Encodage et langue
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
% Décommenter après 'make install' :
% \usepackage[french]{babel}
\usepackage{csquotes}

% Mise en page
\usepackage[margin=2.5cm]{geometry}
\usepackage{setspace}
\onehalfspacing

% Typographie
\usepackage{lmodern}
\usepackage{microtype}

% Mathématiques
\usepackage{amsmath,amssymb,amsthm}

% Figures et tableaux
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{array}

% Liens et références
\usepackage[colorlinks=true,linkcolor=blue!60!black,citecolor=blue!60!black,urlcolor=blue!60!black]{hyperref}

% Bibliographie
\usepackage[numbers,sort&compress]{natbib}

% En-têtes
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\rhead{\small Proposition de stage M2}
\lhead{\small CMAP -- École Polytechnique}
\cfoot{\thepage}

% Couleurs
\usepackage{xcolor}
\definecolor{polytechnique}{RGB}{0,62,92}

% Titre personnalisé
\usepackage{titling}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

\begin{center}
    {\Large\bfseries\color{polytechnique} Proposition de Stage de Master 2}\\[0.5cm]
    {\large Centre de Mathématiques Appliquées (CMAP)}\\
    {\large École Polytechnique}\\[1cm]

    {\LARGE\bfseries Apprentissage de modèles génératifs d'images\\[0.2cm]
    médicales 3D avec peu de données}\\[0.3cm]
    {\large\itshape Fine-tuning de MAISI sur des scanners cérébraux}\\[1.5cm]
\end{center}

\noindent
\begin{tabular}{@{}ll}
    \textbf{Encadrants :} & Josselin Garnier (CMAP, École Polytechnique)\\
                          & Thomas Boulier (CHU Grenoble Alpes, PREDIMED)\\[0.3cm]
    \textbf{Lieu :}       & CMAP, École Polytechnique, Palaiseau\\[0.3cm]
    \textbf{Période :}    & Avril -- Septembre 2026 (6 mois)\\[0.3cm]
    \textbf{Gratification :} & Selon la réglementation en vigueur\\[0.3cm]
    \textbf{Contact :}    & \href{mailto:josselin.garnier@polytechnique.edu}{josselin.garnier@polytechnique.edu}\\
                          & \href{mailto:tboulier@chu-grenoble.fr}{tboulier@chu-grenoble.fr}\\
\end{tabular}

\vspace{1cm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Contexte}

\subsection{Enjeux de l'imagerie médicale et de l'intelligence artificielle}

L'intelligence artificielle, et en particulier l'apprentissage profond, a révolutionné l'analyse d'images médicales ces dernières années. Des modèles de segmentation automatique, de classification et de détection atteignent désormais des performances comparables à celles des experts humains dans de nombreuses tâches cliniques~\cite{litjens2017survey}.

Cependant, l'entraînement de ces modèles nécessite généralement de grandes quantités de données annotées, ce qui pose plusieurs défis en imagerie médicale :
\begin{itemize}
    \item La \textbf{rareté des données} : certaines pathologies sont peu fréquentes, limitant le nombre de cas disponibles ;
    \item Le \textbf{coût de l'annotation} : l'expertise médicale requise pour annoter les images est coûteuse et chronophage ;
    \item Les \textbf{contraintes éthiques et réglementaires} : le partage de données médicales est strictement encadré (RGPD, données de santé).
\end{itemize}

\subsection{Modèles génératifs et données synthétiques}

Les modèles génératifs offrent une solution prometteuse à ces problèmes en permettant de \textbf{synthétiser des images médicales réalistes}. Ces images synthétiques peuvent servir à :
\begin{itemize}
    \item Augmenter les jeux de données d'entraînement ;
    \item Partager des données sans compromettre la vie privée des patients ;
    \item Explorer des scénarios cliniques rares ou hypothétiques.
\end{itemize}

Les \textbf{modèles de diffusion} (Diffusion Models) se sont imposés comme l'état de l'art pour la génération d'images depuis les travaux fondateurs de Ho et al.~\cite{ho2020denoising}. Leur principe repose sur un processus de diffusion qui ajoute progressivement du bruit à une image, puis apprend à inverser ce processus pour générer de nouvelles images à partir de bruit pur.

\subsection{MAISI : un modèle de fondation pour l'imagerie médicale 3D}

En 2024, NVIDIA a publié \textbf{MAISI} (Medical AI for Synthetic Imaging)~\cite{guo2024maisi}, un modèle de diffusion latente capable de générer des images CT (tomodensitométrie) 3D haute résolution jusqu'à $512 \times 512 \times 768$ voxels. Ce modèle a été entraîné sur environ 39\,000 volumes CT et représente, à notre connaissance, le premier modèle de fondation pour la génération d'images médicales 3D à cette échelle.

Une version améliorée, \textbf{MAISI-v2}~\cite{he2025maisi2}, a été proposée en 2025 avec deux innovations majeures :
\begin{itemize}
    \item \textbf{Rectified Flow} : une reformulation du processus de diffusion qui accélère l'inférence d'un facteur 10 à 33 ;
    \item \textbf{Region-specific Contrastive Loss} : une fonction de perte contrastive par région anatomique qui améliore la qualité locale des images générées.
\end{itemize}

Le code source de MAISI est disponible en accès libre\footnote{\url{https://github.com/NVIDIA-Medtech/NV-Generate-CTMR/}}, ouvrant la voie à des travaux de recherche sur l'adaptation de ce modèle à des domaines spécifiques.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Problématique scientifique}

\subsection{Question de recherche}

L'objectif de ce stage est d'étudier la question suivante :

\begin{center}
\fbox{\parbox{0.9\textwidth}{\centering\itshape
Est-il possible d'adapter un modèle génératif pré-entraîné (MAISI) pour apprendre la distribution d'un jeu de données de scanners cérébraux avec un nombre limité d'exemples ?
}}
\end{center}

Cette question s'inscrit dans la problématique plus large du \textbf{transfert d'apprentissage pour les modèles génératifs} (transfer learning for generative models). Alors que le fine-tuning de modèles de fondation est bien établi pour les tâches discriminatives (classification, segmentation), son application aux modèles génératifs en imagerie médicale reste peu explorée.

\subsection{Analogie avec les modèles de fondation discriminatifs}

Pour les tâches de classification ou de segmentation, les modèles de fondation pré-entraînés sur de grands corpus (ImageNet, datasets médicaux larges) peuvent être adaptés à de nouvelles tâches avec très peu d'exemples grâce au \textbf{few-shot learning} ou au \textbf{fine-tuning}. Des modèles comme SAM (Segment Anything Model) ou MedSAM illustrent cette capacité~\cite{kirillov2023segment,ma2024segment}.

La question se pose de savoir si cette propriété se transfère aux modèles génératifs : un modèle comme MAISI, ayant appris une représentation générale de l'anatomie humaine sur des dizaines de milliers de CT, peut-il être adapté efficacement à un sous-domaine spécifique (scanners cérébraux pathologiques) avec seulement quelques centaines d'exemples ?

\subsection{Intérêt pour l'imagerie du traumatisme crânien}

Ce stage s'inscrit dans le cadre du projet \textbf{GenAIPI-TBI} (Generative AI for Predictive Imaging in Traumatic Brain Injury) mené au CHU de Grenoble, qui vise à développer des modèles capables de prédire l'évolution des lésions cérébrales chez les patients traumatisés crâniens.

Le traumatisme crânien représente un enjeu majeur de santé publique : première cause de handicap chez les moins de 35 ans en Europe, avec 2,5 millions de nouveaux cas par an~\cite{maas2017traumatic}. Les données disponibles pour ce projet sont limitées à environ 700 patients et 1\,600 scanners, soit un ordre de grandeur inférieur aux besoins typiques des modèles génératifs.

Avant d'aborder la génération conditionnelle (prédiction temporelle), il est essentiel de valider la faisabilité de l'apprentissage de modèles génératifs sur ce type de données avec peu d'exemples.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Objectifs du stage}

\subsection{Objectif principal}

Évaluer la capacité de MAISI/MAISI-v2 à apprendre la distribution d'un jeu de données de scanners cérébraux via fine-tuning, en fonction du nombre d'exemples d'entraînement.

\subsection{Objectifs secondaires}

\begin{enumerate}
    \item \textbf{Benchmark des stratégies de fine-tuning} : comparer différentes approches d'adaptation (full fine-tuning, fine-tuning partiel, LoRA~\cite{hu2021lora}, etc.) en termes de qualité des images générées et de coût computationnel.

    \item \textbf{Courbes d'apprentissage} : établir la relation entre le nombre d'exemples d'entraînement et la qualité de génération, afin d'estimer le « seuil minimal » de données nécessaires.

    \item \textbf{Analyse des modes de défaillance} : identifier les artefacts ou limitations des images générées (manque de diversité, structures anatomiques incorrectes, etc.).

    \item \textbf{Comparaison avec un entraînement from scratch} : quantifier le gain apporté par le transfert d'apprentissage par rapport à un modèle entraîné uniquement sur le dataset cible.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Données}

\subsection{Dataset principal : CQ-500}

Le dataset \textbf{CQ-500}~\cite{chilamkurthy2018deep}, mis à disposition par Qure.ai, constitue le jeu de données principal de cette étude. Il présente plusieurs avantages :

\begin{itemize}
    \item \textbf{Taille adaptée} : 491 scanners cérébraux (environ 193\,000 coupes), représentatif des contraintes de données en contexte hospitalier ;
    \item \textbf{Pathologies pertinentes} : 205 cas présentent des hémorragies intracrâniennes (sous-durales, extra-durales, intra-parenchymateuses, sous-arachnoïdiennes, intraventriculaires) ;
    \item \textbf{Annotations de qualité} : chaque scan a été annoté par trois radiologistes expérimentés ;
    \item \textbf{Licence ouverte} : CC-BY-NC-SA 4.0, permettant une utilisation en recherche académique.
\end{itemize}

Le dataset est accessible à l'adresse : \url{http://headctstudy.qure.ai/dataset}

\subsection{Datasets complémentaires}

En fonction de l'avancement du stage, des données complémentaires pourront être utilisées :
\begin{itemize}
    \item Données du CHU de Grenoble issues de collaborations avec le Grenoble Institut des Neurosciences (GIN) ;
    \item Données du projet GenAIPI-TBI (environ 700 patients, 1\,600 CT).
\end{itemize}

Ces données non publiques permettront de valider la généralisation des résultats obtenus sur CQ-500.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Méthodologie}

\subsection{Phase 1 : Prise en main et baseline}

\begin{enumerate}
    \item Installation et familiarisation avec MAISI-v2 via le framework MONAI ;
    \item Évaluation du modèle pré-entraîné sur la génération de CT cérébraux (sans fine-tuning) ;
    \item Prétraitement du dataset CQ-500 (recalage, normalisation, extraction de la région cérébrale).
\end{enumerate}

\subsection{Phase 2 : Expériences de fine-tuning}

\begin{enumerate}
    \item Implémentation de différentes stratégies de fine-tuning :
    \begin{itemize}
        \item Fine-tuning complet de tous les paramètres ;
        \item Fine-tuning du décodeur uniquement ;
        \item Adaptation par LoRA (Low-Rank Adaptation) ;
        \item Autres méthodes d'adaptation efficace en paramètres (PEFT).
    \end{itemize}

    \item Expériences avec des sous-ensembles de tailles croissantes :
    \begin{itemize}
        \item $n = 50, 100, 200, 300, 400, 491$ scanners.
    \end{itemize}

    \item Entraînement de modèles from scratch pour comparaison.
\end{enumerate}

\subsection{Phase 3 : Évaluation}

L'évaluation de la qualité des images générées reposera sur plusieurs critères :

\begin{itemize}
    \item \textbf{Métriques quantitatives} :
    \begin{itemize}
        \item Fréchet Inception Distance (FID) adaptée aux images médicales ;
        \item Diversité des images générées (via clustering dans l'espace latent) ;
        \item Consistance anatomique (segmentation automatique des structures cérébrales).
    \end{itemize}

    \item \textbf{Évaluation qualitative} :
    \begin{itemize}
        \item Inspection visuelle par les encadrants ;
        \item Si possible, évaluation par un radiologue (réalisme clinique).
    \end{itemize}
\end{itemize}

\subsection{Phase 4 : Analyse et rédaction}

\begin{enumerate}
    \item Analyse des résultats et identification des facteurs clés de succès/échec ;
    \item Rédaction d'un rapport de stage détaillé ;
    \item Éventuellement, préparation d'une publication scientifique.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Compétences requises et environnement}

\subsection{Profil recherché}

\begin{itemize}
    \item Étudiant(e) en Master 2 de mathématiques appliquées, informatique ou domaine connexe ;
    \item Solides connaissances en \textbf{apprentissage profond} et en \textbf{modèles génératifs} ;
    \item Expérience pratique avec \textbf{PyTorch} ;
    \item Intérêt pour l'imagerie médicale (une expérience préalable est un plus) ;
    \item Autonomie, rigueur scientifique et bonnes capacités rédactionnelles.
\end{itemize}

\subsection{Environnement de travail}

\begin{itemize}
    \item Accès aux ressources de calcul du CMAP (GPU) ;
    \item Possibilité d'accès à des ressources supplémentaires via GRICAD (mésocentre de calcul de Grenoble) ;
    \item Encadrement régulier par les deux co-encadrants ;
    \item Interactions avec l'équipe du projet GenAIPI-TBI au CHU de Grenoble et le Grenoble Institut des Neurosciences.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Perspectives}

Ce stage constitue une première étape vers des travaux plus ambitieux :

\begin{itemize}
    \item \textbf{Génération conditionnelle} : adapter MAISI pour générer des images conditionnées par des paramètres cliniques ou des images antérieures (prédiction de l'évolution des lésions) ;

    \item \textbf{Approches hybrides} : combiner les modèles de diffusion avec des contraintes physiques (Physics-Informed Neural Networks) pour régulariser l'apprentissage avec peu de données ;

    \item \textbf{Thèse de doctorat} : ce stage pourrait déboucher sur une thèse co-encadrée entre le CMAP et le CHU de Grenoble sur la génération prédictive d'images médicales.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Références}

\begingroup
\renewcommand{\section}[2]{}
\begin{thebibliography}{99}

\bibitem{litjens2017survey}
G. Litjens et al.,
``A survey on deep learning in medical image analysis,''
\textit{Medical Image Analysis}, vol. 42, pp. 60--88, 2017.

\bibitem{ho2020denoising}
J. Ho, A. Jain, and P. Abbeel,
``Denoising diffusion probabilistic models,''
\textit{Advances in Neural Information Processing Systems}, vol. 33, pp. 6840--6851, 2020.

\bibitem{guo2024maisi}
P. Guo et al.,
``MAISI: Medical AI for Synthetic Imaging,''
\textit{arXiv preprint arXiv:2409.11169}, 2024.

\bibitem{he2025maisi2}
Y. He et al.,
``MAISI-v2: Accelerated 3D High-Resolution Medical Image Synthesis with Rectified Flow and Region-specific Contrastive Loss,''
\textit{arXiv preprint arXiv:2508.05772}, 2025.

\bibitem{kirillov2023segment}
A. Kirillov et al.,
``Segment anything,''
\textit{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp. 4015--4026, 2023.

\bibitem{ma2024segment}
J. Ma et al.,
``Segment anything in medical images,''
\textit{Nature Communications}, vol. 15, no. 1, p. 654, 2024.

\bibitem{maas2017traumatic}
A. I. R. Maas et al.,
``Traumatic brain injury: integrated approaches to improve prevention, clinical care, and research,''
\textit{The Lancet Neurology}, vol. 16, no. 12, pp. 987--1048, 2017.

\bibitem{chilamkurthy2018deep}
S. Chilamkurthy et al.,
``Deep learning algorithms for detection of critical findings in head CT scans: a retrospective study,''
\textit{The Lancet}, vol. 392, no. 10162, pp. 2388--2396, 2018.

\bibitem{hu2021lora}
E. J. Hu et al.,
``LoRA: Low-rank adaptation of large language models,''
\textit{arXiv preprint arXiv:2106.09685}, 2021.

\end{thebibliography}
\endgroup

\end{document}