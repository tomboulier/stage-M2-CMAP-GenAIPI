\documentclass[11pt,a4paper]{article}

% Encodage et langue
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
% Décommenter après 'make install' :
% \usepackage[french]{babel}
\usepackage{csquotes}

% Mise en page
\usepackage[margin=2.5cm]{geometry}

% Typographie
\usepackage{lmodern}

% Liens
\usepackage[colorlinks=true,linkcolor=blue!60!black,citecolor=blue!60!black,urlcolor=blue!60!black]{hyperref}

% Bibliographie
\usepackage[numbers,sort&compress]{natbib}

% Couleurs
\usepackage{xcolor}
\definecolor{polytechnique}{RGB}{0,62,92}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

\begin{center}
    {\Large\bfseries\color{polytechnique} Proposition de Stage de Master 2}\\[0.3cm]
    {\large CMAP -- École Polytechnique}\\[0.8cm]

    {\LARGE\bfseries Apprentissage de modèles génératifs d'images\\[0.2cm]
    médicales 3D avec peu de données}\\[1cm]
\end{center}

\noindent
\begin{tabular}{@{}ll}
    \textbf{Encadrants :} & Josselin Garnier (CMAP, École Polytechnique)\\
                          & Thomas Boulier (CHU Grenoble Alpes)\\[0.2cm]
    \textbf{Lieu :}       & CMAP, École Polytechnique, Palaiseau\\[0.2cm]
    \textbf{Période :}    & Avril -- Septembre 2026 (6 mois)\\[0.2cm]
    \textbf{Contact :}    & \href{mailto:josselin.garnier@polytechnique.edu}{josselin.garnier@polytechnique.edu},
                            \href{mailto:tboulier@chu-grenoble.fr}{tboulier@chu-grenoble.fr}\\
\end{tabular}

\vspace{0.6cm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Contexte et motivation}

Ce stage s'inscrit dans le projet \textbf{GenAIPI-TBI} (Generative AI for Predictive
Imaging in Traumatic Brain Injury), mené au CHU de Grenoble. Son objectif à long terme est de développer des 
modèles génératifs capables de \textbf{prédire l'évolution} des lésions hémorragiques à partir des scanners 
antérieurs chez des patients ayant subi un traumatisme crânien. Cette pathologie est la première cause de handicap 
chez les moins de 35 ans en Europe~\cite{maas2017tbi}, et sa prise en charge est guidée par l'évaluation
régulière de l'évolution des lésions au scanner cérébral \cite{geeraerts2016sfar}. Disposer de modèles
génératifs capables de simuler l'évolution des lésions à partir d'un scanner initial pourrait ainsi
constituer un outil précieux pour la planification thérapeutique.

Les modèles de diffusion se sont imposés comme l'approche de référence pour la 
génération d'images, tant en vision par ordinateur~\cite{croitoru2023tpami} qu'en 
imagerie médicale~\cite{kazerouni2023media}. Un obstacle majeur à l'utilisation de ces modèles
dans le projet GenAIPI-TBI est la \textbf{rareté des données} : nous disposons en effet d'environ
700 patients et 1\,600 scanners, soit un ordre de grandeur inférieur aux dizaines de
milliers d'exemples typiquement requis par les modèles génératifs. A titre d'exemple,
le modèle \textbf{MAISI} (Medical AI for Synthetic Imaging)~\cite{guo2024maisi}, 
développé par NVIDIA, a été pré-entraîné sur environ 39\,000 volumes de scanners ;
celui de Pinaya et al.~\cite{pinaya2022brain} sur 31\,740 IRM cérébrales.

\textbf{La question fondamentale est donc : peut-on entraîner des modèles génératifs
de qualité avec peu de données ?}

Pour les tâches \emph{discriminatives} (classification, segmentation), le
\textbf{transfer learning} a démontré son efficacité. Par exemple,
BLAST-CT~\cite{monteiro2020blastct}, un outil de segmentation de lésions cérébrales
traumatiques, a été adapté avec seulement 87 scans par Brossard et
al.~\cite{brossard2023til} pour affiner les classes d'hémorragies intra-crâniennes
post-traumatiques.
La question se pose de savoir si une approche similaire fonctionne également pour les
\textbf{modèles génératifs}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Objectif du stage}

Ce stage vise à évaluer si un modèle génératif pré-entraîné peut apprendre la
distribution d'un jeu de données de scanners cérébraux avec un nombre limité
d'exemples.

L'étude s'appuiera sur le jeu de données public
\textbf{CQ-500}~\cite{chilamkurthy2018cq500} (491 scanners cérébraux, dont 205 avec
hémorragies intracrâniennes) pour aborder la question suivante : \textbf{quel est le
nombre minimal d'images d'entraînement nécessaire pour qu'un modèle génératif
pré-entraîné produise, après adaptation, des images atteignant un seuil de qualité
donné ?} Cette question, analogue au calcul du nombre de sujets nécessaires dans les
études cliniques, n'a pas de réponse établie dans le contexte des modèles génératifs
pour l'imagerie médicale.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Etat de l'art}
Plusieurs travaux ont montré que les modèles de diffusion pouvaient être 
adaptés à des régimes de données restreints, en
particulier dans des contextes de \emph{few-shot learning} ou de transfert
depuis un pré-entraînement à grande échelle. Cao et Gong~\cite{cao2024fewshot}
proposent ainsi une méthode de génération d'images en few-shot reposant sur
l'inversion conditionnelle de modèles de diffusion, permettant d'obtenir des
résultats satisfaisants à partir d'un très petit nombre d'exemples cibles. De
manière complémentaire, Hu et al.~\cite{hu2023phasic} introduisent une stratégie
d'adaptation progressive de modèles de diffusion spécifiquement conçue pour
limiter le sur-apprentissage lorsque le nombre de données disponibles est
extrêmement réduit. Par ailleurs, d'un point de vue plus théorique, Chen et
al.~\cite{chen2022sampling} montrent que les modèles de diffusion peuvent
fournir des garanties d'échantillonnage sous des hypothèses relativement faibles
sur l'estimation du score, apportant ainsi un éclairage important sur leur
efficacité en termes de complexité en données. Enfin, les modèles de diffusion
ont également été interprétés comme des \emph{priors} génératifs génériques
pouvant être intégrés dans des cadres d'inférence plus larges, notamment pour
des problèmes inverses, comme le montrent Graikos et
al.~\cite{graikos2022plugandplay}, ouvrant la voie à des approches modulaires
combinant pré-entraînement massif et adaptation à des tâches spécifiques.

Ces travaux fournissent un cadre conceptuel solide pour étudier, dans le
contexte de ce projet, la relation entre pré-entraînement génératif, taille des
jeux de données cliniques disponibles et performances atteignables.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Profil recherché}

\begin{itemize}
    \item Master 2 en mathématiques appliquées, informatique ou domaine connexe
    \item Connaissances en apprentissage profond et modèles génératifs
    \item Compétences en programmation Python, Expérience avec PyTorch et/ou TensorFlow
    \item Intérêt pour l'imagerie médicale
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\renewcommand{\refname}{Références}
\bibliographystyle{unsrtnat}
\begin{thebibliography}{9}

\bibitem{maas2017tbi}
A.I.R. Maas et al.,
\emph{Traumatic brain injury: integrated approaches to improve prevention, clinical care, and research},
The Lancet Neurology, 16(12):987--1048, 2017.

\bibitem{geeraerts2016sfar}
Geeraerts, Thomas, et al. 
\emph{Prise en charge des traumatisés crâniens graves à la phase précoce (24 premières heures).}
Anesth Reanim (2.6:431-53), 2016.

\bibitem{croitoru2023tpami}
F.A. Croitoru, V. Hondru, R.T. Ionescu, M. Shah,
\emph{Diffusion Models in Vision: A Survey},
IEEE Transactions on Pattern Analysis and Machine Intelligence, 45(9):10850--10869, 2023.

\bibitem{kazerouni2023media}
A. Kazerouni, E.K. Aghdam, M. Heidari, R. Azad, M. Fayyaz, I. Hacihaliloglu, D. Merhof,
\emph{Diffusion Models in Medical Imaging: A Comprehensive Survey},
Medical Image Analysis, 88:102846, 2023.

\bibitem{guo2024maisi}
P. Guo et al.,
\emph{MAISI: Medical AI for Synthetic Imaging},
arXiv:2409.11169, 2024.

\bibitem{pinaya2022brain}
W.H.L. Pinaya, P.-D. Tudosiu, J. Dafflon, P.F. Da Costa, V. Fernandez, P. Nachev, S. Ourselin, M.J. Cardoso,
\emph{Brain Imaging Generation with Latent Diffusion Models},
MICCAI Workshop on Deep Generative Models, pp.~117--126, Springer, 2022.

\bibitem{monteiro2020blastct}
M. Monteiro et al.,
\emph{Multiclass semantic segmentation and quantification of traumatic brain injury lesions on head CT using deep learning},
The Lancet Digital Health, 2(6):e314--e322, 2020.

\bibitem{brossard2023til}
C. Brossard et al.,
\emph{Prediction of therapeutic intensity level from automatic multiclass segmentation of traumatic brain injury lesions on CT-scans},
Scientific Reports, 13:19536, 2023.

\bibitem{chilamkurthy2018cq500}
S. Chilamkurthy et al.,
\emph{Deep learning algorithms for detection of critical findings in head CT scans: a retrospective study},
The Lancet, 392(10162):2388--2396, 2018.

\bibitem{cao2024fewshot}
Y. Cao, S. Gong,
\emph{Few-Shot Image Generation by Conditional Relaxing Diffusion Inversion},
European Conference on Computer Vision (ECCV), pp.~20--37, Springer, 2024.

\bibitem{hu2023phasic}
T. Hu, J. Zhang, L. Liu, R. Yi, S. Kou, H. Zhu, X. Chen, Y. Wang, C. Wang, L. Ma,
\emph{Phasic Content Fusing Diffusion Model with Directional Distribution Consistency for Few-Shot Model Adaption},
IEEE/CVF International Conference on Computer Vision (ICCV), pp.~2406--2415, 2023.

\bibitem{chen2022sampling}
S. Chen, S. Chewi, J. Li, Y. Li, A. Salim, A.R. Zhang,
\emph{Sampling is as Easy as Learning the Score: Theory for Diffusion Models with Minimal Data Assumptions},
International Conference on Learning Representations (ICLR), 2023.

\bibitem{graikos2022plugandplay}
A. Graikos, N. Malkin, N. Jojic, D. Samaras,
\emph{Diffusion Models as Plug-and-Play Priors},
Advances in Neural Information Processing Systems (NeurIPS), 35:14715--14728, 2022.

\end{thebibliography}

\end{document}
