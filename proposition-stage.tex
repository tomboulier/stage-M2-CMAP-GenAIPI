\documentclass[11pt,a4paper]{article}

% Encodage et langue
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
% Décommenter après 'make install' :
% \usepackage[french]{babel}
\usepackage{csquotes}

% Mise en page
\usepackage[margin=2.5cm]{geometry}

% Typographie
\usepackage{lmodern}

% Liens
\usepackage[colorlinks=true,linkcolor=blue!60!black,citecolor=blue!60!black,urlcolor=blue!60!black]{hyperref}

% Bibliographie
\usepackage[numbers,sort&compress]{natbib}

% Couleurs
\usepackage{xcolor}
\definecolor{polytechnique}{RGB}{0,62,92}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

\begin{center}
    {\Large\bfseries\color{polytechnique} Proposition de Stage de Master 2}\\[0.3cm]
    {\large CMAP -- École Polytechnique}\\[0.8cm]

    {\LARGE\bfseries Apprentissage de modèles génératifs d'images\\[0.2cm]
    médicales 3D avec peu de données}\\[1cm]
\end{center}

\noindent
\begin{tabular}{@{}ll}
    \textbf{Encadrants :} & Josselin Garnier (CMAP, École Polytechnique)\\
                          & Thomas Boulier (CHU Grenoble Alpes)\\[0.2cm]
    \textbf{Lieu :}       & CMAP, École Polytechnique, Palaiseau\\[0.2cm]
    \textbf{Période :}    & Avril -- Septembre 2026 (6 mois)\\[0.2cm]
    \textbf{Contact :}    & \href{mailto:josselin.garnier@polytechnique.edu}{josselin.garnier@polytechnique.edu},
                            \href{mailto:tboulier@chu-grenoble.fr}{tboulier@chu-grenoble.fr}\\
\end{tabular}

\vspace{0.6cm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Contexte et motivation}

Ce stage s'inscrit dans le projet \textbf{GenAIPI-TBI} (Generative AI for Predictive Imaging in Traumatic Brain Injury), mené au CHU de Grenoble. L'objectif à long terme est de développer des modèles génératifs capables de \textbf{prédire l'évolution des lésions cérébrales} chez les patients traumatisés crâniens à partir d'images CT successives. Le traumatisme crânien est la première cause de handicap chez les moins de 35 ans en Europe~\cite{maas2017tbi}.

Un obstacle majeur est la \textbf{rareté des données} : le projet dispose d'environ 700 patients et 1\,600 scanners, soit un ordre de grandeur inférieur aux dizaines de milliers d'exemples typiquement requis par les modèles génératifs. Cette contrainte est renforcée par le \textbf{principe de minimisation} du RGPD (article 5)~\cite{rgpd2016}, qui impose de limiter la collecte de données personnelles au strict nécessaire.

\textbf{La question fondamentale est donc : peut-on entraîner des modèles génératifs de qualité avec peu de données ?}

Pour les tâches \emph{discriminatives} (classification, segmentation), le \textbf{transfer learning} a démontré son efficacité. Par exemple, BLAST-CT~\cite{monteiro2020blastct}, un outil de segmentation de lésions cérébrales traumatiques, a été adapté avec seulement 87 scans par Brossard et al.~\cite{brossard2023til} pour prédire l'intensité thérapeutique en réanimation. La question se pose de savoir si cette approche fonctionne également pour les \textbf{modèles génératifs de fondation}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Objectif du stage}

Ce stage vise à évaluer si un modèle génératif pré-entraîné peut apprendre la distribution d'un jeu de données de scanners cérébraux avec un nombre limité d'exemples.

Le modèle étudié sera \textbf{MAISI} (Medical AI for Synthetic Imaging)~\cite{guo2024maisi}, développé par NVIDIA. MAISI est un modèle de diffusion latente capable de générer des images CT 3D haute résolution (jusqu'à $512 \times 512 \times 768$ voxels), pré-entraîné sur environ 39\,000 volumes. Une version améliorée, MAISI-v2~\cite{zhao2025maisiv2}, propose une accélération d'un facteur 10 à 33 grâce au \emph{rectified flow}.

L'étude portera sur le \textbf{fine-tuning} de ce modèle sur le dataset \textbf{CQ-500}~\cite{chilamkurthy2018cq500} (491 scanners cérébraux, dont 205 avec hémorragies intracrâniennes), afin de mesurer la qualité de génération en fonction du nombre d'exemples d'entraînement.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Profil recherché}

\begin{itemize}
    \item Master 2 en mathématiques appliquées, informatique ou domaine connexe
    \item Connaissances en apprentissage profond et modèles génératifs
    \item Expérience avec PyTorch
    \item Intérêt pour l'imagerie médicale
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\renewcommand{\refname}{Références}
\bibliographystyle{unsrtnat}
\begin{thebibliography}{9}

\bibitem{maas2017tbi}
A.I.R. Maas et al.,
\emph{Traumatic brain injury: integrated approaches to improve prevention, clinical care, and research},
The Lancet Neurology, 16(12):987--1048, 2017.

\bibitem{rgpd2016}
Règlement (UE) 2016/679 du Parlement européen et du Conseil (RGPD), article 5 -- Principes relatifs au traitement des données à caractère personnel, 2016.

\bibitem{monteiro2020blastct}
M. Monteiro et al.,
\emph{Multiclass semantic segmentation and quantification of traumatic brain injury lesions on head CT using deep learning},
The Lancet Digital Health, 2(6):e314--e322, 2020.

\bibitem{brossard2023til}
C. Brossard et al.,
\emph{Prediction of therapeutic intensity level from automatic multiclass segmentation of traumatic brain injury lesions on CT-scans},
Scientific Reports, 13:19536, 2023.

\bibitem{guo2024maisi}
P. Guo et al.,
\emph{MAISI: Medical AI for Synthetic Imaging},
arXiv:2409.11169, 2024.

\bibitem{zhao2025maisiv2}
C. Zhao et al.,
\emph{MAISI-v2: Accelerated 3D High-Resolution Medical Image Synthesis with Rectified Flow and Region-specific Contrastive Loss},
arXiv:2508.05772, 2025.

\bibitem{chilamkurthy2018cq500}
S. Chilamkurthy et al.,
\emph{Deep learning algorithms for detection of critical findings in head CT scans: a retrospective study},
The Lancet, 392(10162):2388--2396, 2018.
DOI: 10.1016/S0140-6736(18)31645-3.

\end{thebibliography}

\end{document}
