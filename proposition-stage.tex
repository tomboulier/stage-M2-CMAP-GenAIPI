\documentclass[11pt,a4paper]{article}

% Encodage et langue
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
% Décommenter après 'make install' :
% \usepackage[french]{babel}
\usepackage{csquotes}

% Mise en page
\usepackage[margin=2.5cm]{geometry}

% Typographie
\usepackage{lmodern}

% Liens
\usepackage[colorlinks=true,linkcolor=blue!60!black,citecolor=blue!60!black,urlcolor=blue!60!black]{hyperref}

% Bibliographie
\usepackage[numbers,sort&compress]{natbib}

% Couleurs
\usepackage{xcolor}
\definecolor{polytechnique}{RGB}{0,62,92}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

\begin{center}
    {\Large\bfseries\color{polytechnique} Proposition de Stage de Master 2}\\[0.3cm]
    {\large CMAP -- École Polytechnique}\\[0.8cm]

    {\LARGE\bfseries Apprentissage de modèles génératifs d'images\\[0.2cm]
    médicales 3D avec peu de données}\\[1cm]
\end{center}

\noindent
\begin{tabular}{@{}ll}
    \textbf{Encadrants :} & Josselin Garnier (CMAP, École Polytechnique)\\
                          & Thomas Boulier (CHU Grenoble Alpes)\\[0.2cm]
    \textbf{Lieu :}       & CMAP, École Polytechnique, Palaiseau\\[0.2cm]
    \textbf{Période :}    & Avril -- Septembre 2026 (6 mois)\\[0.2cm]
    \textbf{Contact :}    & \href{mailto:josselin.garnier@polytechnique.edu}{josselin.garnier@polytechnique.edu},
                            \href{mailto:tboulier@chu-grenoble.fr}{tboulier@chu-grenoble.fr}\\
\end{tabular}

\vspace{0.6cm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Contexte et motivation}

Ce stage s'inscrit dans le projet \textbf{GenAIPI-TBI} (Generative AI for Predictive
Imaging in Traumatic Brain Injury), mené au CHU de Grenoble. Le traumatisme crânien est la première cause de handicap chez les moins
de 35 ans en Europe~\cite{maas2017tbi}, et sa prise en charge est guidée par l'évaluation
régulière de l'évolution des lésions hémorragiques au scanner cérébral \cite{geeraerts2016sfar}. 
L'objectif à long terme est de développer des modèles génératifs capables de \textbf{prédire l'évolution}
de ces lésions à partir des scanners antérieurs.

Un obstacle majeur est la \textbf{rareté des données} : le projet dispose d'environ
700 patients et 1\,600 scanners, soit un ordre de grandeur inférieur aux dizaines de
milliers d'exemples typiquement requis par les modèles génératifs. A titre d'exemple,
le modèle \textbf{MAISI} (Medical AI for Synthetic Imaging)~\cite{guo2024maisi}, 
développé par NVIDIA, a été pré-entraîné sur environ 39\,000 volumes de scanners ;
celui de Pinaya et al.~\cite{pinaya2022brain} sur 31\,740 IRM cérébrales.

\textbf{La question fondamentale est donc : peut-on entraîner des modèles génératifs
de qualité avec peu de données ?}

Pour les tâches \emph{discriminatives} (classification, segmentation), le
\textbf{transfer learning} a démontré son efficacité. Par exemple,
BLAST-CT~\cite{monteiro2020blastct}, un outil de segmentation de lésions cérébrales
traumatiques, a été adapté avec seulement 87 scans par Brossard et
al.~\cite{brossard2023til} pour affiner les classes d'hémorragies intra-crâniennes
post-traumatiques.
La question se pose de savoir si cette approche fonctionne également pour les
\textbf{modèles génératifs de fondation}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Objectif du stage}

Ce stage vise à évaluer si un modèle génératif pré-entraîné peut apprendre la
distribution d'un jeu de données de scanners cérébraux avec un nombre limité
d'exemples.

L'étude s'appuiera sur le jeu de données public
\textbf{CQ-500}~\cite{chilamkurthy2018cq500} (491 scanners cérébraux, dont 205 avec
hémorragies intracrâniennes) pour aborder la question suivante : \textbf{quel est le
nombre minimal d'images d'entraînement nécessaire pour qu'un modèle génératif
pré-entraîné produise, après adaptation, des images atteignant un seuil de qualité
donné ?} Cette question, analogue au calcul du nombre de sujets nécessaires dans les
études cliniques, n'a pas de réponse établie dans le contexte des modèles génératifs
pour l'imagerie médicale.

Plusieurs travaux ont montré que les modèles de diffusion pouvaient être 
adaptés à des régimes de données restreints, en
particulier dans des contextes de \emph{few-shot learning} ou de transfert
depuis un pré-entraînement à grande échelle. Cao et Gong~\cite{cao2024fewshot}
proposent ainsi une méthode de génération d'images en few-shot reposant sur
l'inversion conditionnelle de modèles de diffusion, permettant d'obtenir des
résultats satisfaisants à partir d'un très petit nombre d'exemples cibles. De
manière complémentaire, Hu et al.~\cite{hu2023phasic} introduisent une stratégie
d'adaptation progressive de modèles de diffusion spécifiquement conçue pour
limiter le sur-apprentissage lorsque le nombre de données disponibles est
extrêmement réduit. Par ailleurs, d'un point de vue plus théorique, Chen et
al.~\cite{chen2022sampling} montrent que les modèles de diffusion peuvent
fournir des garanties d'échantillonnage sous des hypothèses relativement faibles
sur l'estimation du score, apportant ainsi un éclairage important sur leur
efficacité en termes de complexité en données. Enfin, les modèles de diffusion
ont également été interprétés comme des \emph{priors} génératifs génériques
pouvant être intégrés dans des cadres d'inférence plus larges, notamment pour
des problèmes inverses, comme le montrent Graikos et
al.~\cite{graikos2022plugandplay}, ouvrant la voie à des approches modulaires
combinant pré-entraînement massif et adaptation à des tâches spécifiques.

Ces travaux fournissent un cadre conceptuel solide pour étudier, dans le
contexte de ce projet, la relation entre pré-entraînement génératif, taille des
jeux de données cliniques disponibles et performances atteignables.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Profil recherché}

\begin{itemize}
    \item Master 2 en mathématiques appliquées, informatique ou domaine connexe
    \item Connaissances en apprentissage profond et modèles génératifs
    \item Compétences en programmation Python, Expérience avec PyTorch et/ou TensorFlow
    \item Intérêt pour l'imagerie médicale
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\renewcommand{\refname}{Références}
\bibliographystyle{unsrtnat}
\begin{thebibliography}{9}

\bibitem{maas2017tbi}
A.I.R. Maas et al.,
\emph{Traumatic brain injury: integrated approaches to improve prevention, clinical care, and research},
The Lancet Neurology, 16(12):987--1048, 2017.

\bibitem{geeraerts2016sfar}
Geeraerts, Thomas, et al. 
\emph{Prise en charge des traumatisés crâniens graves à la phase précoce (24 premières heures).}
Anesth Reanim (2.6:431-53), 2016.

\bibitem{rgpd2016}
Règlement (UE) 2016/679 du Parlement européen et du Conseil (RGPD), article 5 -- Principes relatifs au traitement des données à caractère personnel, 2016.

\bibitem{monteiro2020blastct}
M. Monteiro et al.,
\emph{Multiclass semantic segmentation and quantification of traumatic brain injury lesions on head CT using deep learning},
The Lancet Digital Health, 2(6):e314--e322, 2020.

\bibitem{brossard2023til}
C. Brossard et al.,
\emph{Prediction of therapeutic intensity level from automatic multiclass segmentation of traumatic brain injury lesions on CT-scans},
Scientific Reports, 13:19536, 2023.

\bibitem{guo2024maisi}
P. Guo et al.,
\emph{MAISI: Medical AI for Synthetic Imaging},
arXiv:2409.11169, 2024.

\bibitem{zhao2025maisiv2}
C. Zhao et al.,
\emph{MAISI-v2: Accelerated 3D High-Resolution Medical Image Synthesis with Rectified Flow and Region-specific Contrastive Loss},
arXiv:2508.05772, 2025.

\bibitem{chilamkurthy2018cq500}
S. Chilamkurthy et al.,
\emph{Deep learning algorithms for detection of critical findings in head CT scans: a retrospective study},
The Lancet, 392(10162):2388--2396, 2018.

% Références état de l'art modèles de diffusion

\bibitem{pinaya2022brain}
W.H.L. Pinaya, P.-D. Tudosiu, J. Dafflon, P.F. Da Costa, V. Fernandez, P. Nachev, S. Ourselin, M.J. Cardoso,
\emph{Brain Imaging Generation with Latent Diffusion Models},
MICCAI Workshop on Deep Generative Models, pp.~117--126, Springer, 2022.

\bibitem{wolleb2022anomaly}
J. Wolleb, F. Bieder, R. Sandkühler, P.C. Cattin,
\emph{Diffusion Models for Medical Anomaly Detection},
Medical Image Computing and Computer Assisted Intervention -- MICCAI 2022, pp.~35--45, Springer, 2022.

\bibitem{khan2025survey}
W. Khan, S. Leem, K.B. See, J.K. Wong, S. Zhang, R. Fang,
\emph{A Comprehensive Survey of Foundation Models in Medicine},
IEEE Reviews in Biomedical Engineering, 2025.

\bibitem{cao2024fewshot}
Y. Cao, S. Gong,
\emph{Few-Shot Image Generation by Conditional Relaxing Diffusion Inversion},
European Conference on Computer Vision (ECCV), pp.~20--37, Springer, 2024.

\bibitem{hu2023phasic}
T. Hu, J. Zhang, L. Liu, R. Yi, S. Kou, H. Zhu, X. Chen, Y. Wang, C. Wang, L. Ma,
\emph{Phasic Content Fusing Diffusion Model with Directional Distribution Consistency for Few-Shot Model Adaption},
IEEE/CVF International Conference on Computer Vision (ICCV), pp.~2406--2415, 2023.

\bibitem{chen2022sampling}
S. Chen, S. Chewi, J. Li, Y. Li, A. Salim, A.R. Zhang,
\emph{Sampling is as Easy as Learning the Score: Theory for Diffusion Models with Minimal Data Assumptions},
International Conference on Learning Representations (ICLR), 2023.

\bibitem{graikos2022plugandplay}
A. Graikos, N. Malkin, N. Jojic, D. Samaras,
\emph{Diffusion Models as Plug-and-Play Priors},
Advances in Neural Information Processing Systems (NeurIPS), 35:14715--14728, 2022.

\end{thebibliography}

\end{document}
